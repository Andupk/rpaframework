###################
Robot Framework API
###################

***********
Description
***********

:Library scope: Global

`AWS` is a library for operating with Amazon AWS services S3, SQS,
Textract and Comprehend.

Services are initialized with keywords like ``Init S3 Client`` for S3.

**AWS authentication**

Authentication for AWS is set with `key id` and `access key` which can be given to the library
in three different ways.

- Method 1 as environment variables, ``AWS_KEY_ID`` and ``AWS_KEY``.
- Method 2 as keyword parameters to ``Init Textract Client`` for example.
- Method 3 as Robocloud vault secret. The vault name needs to be given in library init or
  with keyword ``Set Robocloud Vault``. Secret keys are expected to match environment variable
  names.

Method 1. credentials using environment variable

.. code-block:: robotframework

    *** Settings ***
    Library   RPA.Cloud.AWS

    *** Tasks ***
    Init AWS services
        # NO parameters for client, expecting to get credentials
        # with AWS_KEY and AWS_KEY_ID environment variable
        Init S3 Client

Method 2. credentials with keyword parameter

.. code-block:: robotframework

    *** Settings ***
    Library   RPA.Cloud.AWS

    *** Tasks ***
    Init AWS services
        Init S3 Client  aws_key_id=${AWS_KEY_ID}  aws_key=${AWS_KEY}

Method 3. setting Robocloud Vault in the library init

.. code-block:: robotframework

    *** Settings ***
    Library   RPA.Cloud.AWS  robocloud_vault_name=aws

    *** Tasks ***
    Init AWS services
        Init S3 Client  use_robocloud_vault=${TRUE}

Method 3. setting Robocloud Vault with keyword

.. code-block:: robotframework

    *** Settings ***
    Library   RPA.Cloud.AWS

    *** Tasks ***
    Init Azure services
        Set Robocloud Vault         vault_name=aws
        Init Textract Client  use_robocloud_vault=${TRUE}

**Requirements**

The default installation depends on `boto3`_ library. Due to the size of the
dependency, this library has been set as an optional package for ``rpaframework``.

This can be installed by opting in to the `aws` dependency:

``pip install rpaframework[aws]``

.. _boto3:
    https://boto3.amazonaws.com/v1/documentation/api/latest/index.html

**Example**

.. code-block:: robotframework

    *** Settings ***
    Library   RPA.Cloud.AWS   region=us-east-1

    *** Variables ***
    ${BUCKET_NAME}        testbucket12213123123

    *** Tasks ***
    Upload a file into S3 bucket
        [Setup]   Init S3 Client
        Upload File      ${BUCKET_NAME}   ${/}path${/}to${/}file.pdf
        @{files}         List Files   ${BUCKET_NAME}
        FOR   ${file}  IN   @{files}
            Log  ${file}
        END

********
Keywords
********

:Analyze Document:
  :Arguments: image_file: str = None, json_file: str = None, bucket_name: str = None

  Analyzes an input document for relationships between detected items


:Create Bucket:
  :Arguments: bucket_name: str = None

  Create S3 bucket with name


:Create Queue:
  :Arguments: queue_name: str = None

  Create queue with name


:Delete Bucket:
  :Arguments: bucket_name: str = None

  Delete S3 bucket with name


:Delete Files:
  :Arguments: bucket_name: str = None, files: list = None

  Delete files in the bucket


:Delete Message:
  :Arguments: receipt_handle: str = None

  Delete message in the queue


:Delete Queue:
  :Arguments: queue_name: str = None

  Delete queue with name


:Detect Document Text:
  :Arguments: image_file: str = None, json_file: str = None, bucket_name: str = None

  Detects text in the input document.


:Detect Entities:
  :Arguments: text: str = None, lang=en

  Inspects text for named entities, and returns information about them


:Detect Sentiment:
  :Arguments: text: str = None, lang=en

  Inspects text and returns an inference of the prevailing sentiment


:Download Files:
  :Arguments: bucket_name: str = None, files: list = None, target_directory: str = None

  Download files from bucket to local filesystem


:Get Cells:
  [summary]


:Get Document Analysis:
  :Arguments: job_id: str = None, max_results: int = 1000, next_token: str = None

  Get the results of Textract asynchronous `Document Analysis` operation


  Response dictionary has key `JobStatus` with value `SUCCEEDED` when analysis
  has been completed.

  Example:

  .. code-block:: robotframework

      Init Textract Client  %{AWS_KEY_ID}  %{AWS_KEY_SECRET}  %{AWS_REGION}
      ${jobid}=    Start Document Analysis  s3bucket_name  invoice.pdf
      FOR    ${i}    IN RANGE    50
          ${response}    Get Document Analysis  ${jobid}
          Exit For Loop If    "${response}[JobStatus]" == "SUCCEEDED"
          Sleep    1s
      END

:Get Document Text Detection:
  :Arguments: job_id: str = None, max_results: int = 1000, next_token: str = None

  Get the results of Textract asynchronous `Document Text Detection` operation


  Response dictionary has key `JobStatus` with value `SUCCEEDED` when analysis
  has been completed.

  Example:

  .. code-block:: robotframework

      Init Textract Client  %{AWS_KEY_ID}  %{AWS_KEY_SECRET}  %{AWS_REGION}
      ${jobid}=    Start Document Text Detection  s3bucket_name  invoice.pdf
      FOR    ${i}    IN RANGE    50
          ${response}    Get Document Text Detection    ${jobid}
          Exit For Loop If    "${response}[JobStatus]" == "SUCCEEDED"
          Sleep    1s
      END

:Get Pages And Text:
  :Arguments: textract_response: dict

  Get pages and text out of Textract response json


:Get Tables:
  [summary]


:Get Words:
  [summary]


:Init Comprehend Client:
  :Arguments: aws_key_id: str = None, aws_key: str = None, region: str = None, use_robocloud_vault: bool = False

  Initialize AWS Comprehend client


:Init S3 Client:
  :Arguments: aws_key_id: str = None, aws_key: str = None, region: str = None, use_robocloud_vault: bool = False

  Initialize AWS S3 client


:Init Sqs Client:
  :Arguments: aws_key_id: str = None, aws_key: str = None, region: str = None, queue_url: str = None, use_robocloud_vault: bool = False

  Initialize AWS SQS client


:Init Textract Client:
  :Arguments: aws_key_id: str = None, aws_key: str = None, region: str = None, use_robocloud_vault: bool = False

  Initialize AWS Textract client


:List Buckets:
  List all buckets for this account


:List Files:
  :Arguments: bucket_name

  List files in the bucket


:Receive Message:
  Receive message from queue


:Send Message:
  :Arguments: message: str = None, message_attributes: dict = None

  Send message to the queue


:Set Robocloud Vault:
  :Arguments: vault_name

  Set Robocloud Vault name


:Start Document Analysis:
  :Arguments: bucket_name_in: str = None, object_name_in: str = None, object_version_in: str = None, bucket_name_out: str = None, prefix_object_out: str = textract_output

  Starts the asynchronous analysis of an input document
  for relationships between detected items such as key-value pairs,
  tables, and selection elements.


  Input object can be in JPEG, PNG or PDF format. Documents should
  be located in the Amazon S3 bucket.

  By default Amazon Textract will save the analysis result internally
  to be accessed by keyword ``Get Document Analysis``. This can
  be overridden by giving parameter ``bucket_name_out``.

:Start Document Text Detection:
  :Arguments: bucket_name_in: str = None, object_name_in: str = None, object_version_in: str = None, bucket_name_out: str = None, prefix_object_out: str = textract_output

  Starts the asynchronous detection of text in a document.
  Amazon Textract can detect lines of text and the words that make up a
  line of text.


  Input object can be in JPEG, PNG or PDF format. Documents should
  be located in the Amazon S3 bucket.

  By default Amazon Textract will save the analysis result internally
  to be accessed by keyword ``Get Document Text Detection``. This can
  be overridden by giving parameter ``bucket_name_out``.

:Upload File:
  :Arguments: bucket_name: str = None, filename: str = None, object_name: str = None

  Upload single file into bucket


  If `object_name` is not given then basename of the file is
  used as `object_name`.

:Upload Files:
  :Arguments: bucket_name: str = None, files: list = None

  Upload multiple files into bucket


  Giving files as list of filepaths:
      ['/path/to/file1.txt', '/path/to/file2.txt']

  Giving files as list of dictionaries (including filepath and object name):
      [{'filepath':'/path/to/file1.txt', 'object_name': 'file1.txt'},
      {'filepath': '/path/to/file2.txt', 'object_name': 'file2.txt'}]
